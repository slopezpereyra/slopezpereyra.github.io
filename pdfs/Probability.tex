\documentclass[a4paper, 12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{newtxtext} \usepackage{newtxmath}
\usepackage{amsmath, amssymb}
\newtheorem{problem}{Problem}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{problem}{Problem}
\newtheorem{example}{Example} \newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}

\begin{document}

\section{Read me}

These notes are extremely limited and sketchy. The reason is that I was familiar
with probability theory before taking this class. Thus, I did not need to take
many notes. My fellow student will do good in using this document only to
corroborate exercises, problems, and final exams. 

\section{Preliminaries}

Let $\Omega$ denote the sample space of an experiment; i.e. the set of all
values which may result from an experiment. If $A \subseteq \Omega$ we say $A$
is an event. If $\mathcal{A}$ is a $\sigma$-algebra over $\Omega$ we say
$\mathcal{A}$ is a family of events. 

\begin{quote}
    A $\sigma$-algebra on a set $X$ is a non-empty collection of subsets of $X$
    that is closed under complement, countable unions and countable
    intersections. It is usual to take $\mathcal{A} = \mathcal{P}(\Omega)$.
\end{quote}

As usual, if $\mathcal{A}$ a $\sigma$-algebra over $\Omega$, for every $A \in
\mathcal{A}$ we define $P(A)$ as the function that satisfies the following
axioms: 

\begin{itemize}
    \item $P(A) \geq 0$ 
    \item $P(\Omega) = 1$ 
    \item If $A_1, A_2, \ldots \in \Omega, A_i \cap A_j = \emptyset$  for all
        $i \neq j$, then 

        \begin{align*}
            P(A_1 \cup A_2 \cup  \ldots) = \sum_{i=1}^{\infty} P(A_i)
        \end{align*}
\end{itemize}

A probabilistic model is a 3-uple $(\Omega, \mathcal{A}, P)$. We will assume
from now on that $\Omega$ refers to a sample space, $\mathcal{A}$ to
$\mathcal{P}(\Omega)$, and $P$ to the probability function.

A random variable is a function $X : \Omega \mapsto \mathbb{R}$.

\section{Elementary laws}

\subsection{Union, intersection, conditionality, etc.}

This is a collection of notes. Their justification should be intuitively
accessible if one stops and think of their formulas in terms of the subspaces of
$\Omega$ involved.

Let $A, B \in \Omega$. The probability that $A$ occurs given that $B$ has
occurred is 

\begin{align*}
    P(A \mid B) = \frac{P (A \cap B)}{P(B)}
\end{align*}    

Observe that this gives a formula for $P(A \cap B)$. Furthermore, 

\begin{align*}
    P(A \cap B) = P(A)P(B \mid A) = P(B)P(A \mid B)
\end{align*}

If $A, B$ are independent, $P(A \cap B) = P(A)P(B)$.

\begin{align*}
    P(A \cup B) = P(A) + P(B) - P(A \cap B)
\end{align*}

If $A, B$ are mutually exclusive then $P(A \cap B) = \emptyset$ and $P(A \cup B)
= P(A) + P(B)$.

It is useful to remember the following property too. Since $P(A \cup B) = P(A) +
P(B)$ we have that $P((A \cap B) \cup (A - B)) = P(A \cap B) + P(A - B)$, which
implies 

\begin{align*}
    P(A - B) = P(A) - P(A \cap B)
\end{align*}

\subsection{The law of total probability and Bayes' rule}

Let $B_1, \ldots, B_k$, $k \in \mathbb{N}$, s.t. 

\begin{align*}
    \Omega = B_1 \cup \ldots \cup B_k \\ 
    \forall i, j \in [1, k] : i \neq j : B_i \cap  B_j = \emptyset
\end{align*}

Then $\left\{ B_1, \ldots, B_k \right\} $ is a partition of $\Omega$. If $A
\subseteq \Omega$ then it can be decomposed using a partition $\{B_1, \ldots,
B_k\}$ as $A = (A \cap B_1) \cup \ldots (A \cap B_k)$.

\begin{theorem}
    If $\left\{ B_1, \ldots, B_k \right\} $, $k \in \mathbb{N}$, is a partition
    of $\Omega$ s.t. $P(B_i) > 0$ for all $1\leq i \leq k$, then for any $A
    \subseteq \Omega$

    \begin{align*}
        P(A) = \sum_{i=1}^{k} P(A \mid B_i) P(B_i)
    \end{align*}
\end{theorem}


\small
\begin{quote}

\textbf{Proof.} Let $A \subseteq \Omega$. Because $B_1, \ldots, B_k$ partition
$\Omega$, $(A \cap B_i) \cap  (A \cap B_j) = A \cap \emptyset = \emptyset$.
Thus, the two events are mutually exclusive. Thus

\begin{align*}
    P(A) &= P \left( \left( A \cap B_1 \right) \cup \ldots \left( A \cap B_k
    \right)   \right)  \\ 
        &= P(A \cap B_1) + \ldots + P(A \cap B_k) \\ 
        &= \sum_{i=1}^{k} P(A \mid B_i)P(B_i)
\end{align*}

\end{quote}
\normalsize

\begin{theorem}[Bayes' Rule]
    Assume $\left\{ B_1, \ldots, B_k \right\} $ is a partition of $\Omega$ and
    $P(B_i) > 0, i = 1, \ldots, k$. Then 

    \begin{align*}
        P(B_j \mid A) = \frac{P(A \mid B_j) P(B_j)}{\sum_{i=1}^{k}P(A \mid
        B_i)P(B_i)}
    \end{align*}
\end{theorem}

The proof follows from the definition of conditional probability and the law of
total probability.


\section{Discrete random variables}

A random variable $X : \mathcal{D}_X \subseteq  \Omega \mapsto \mathbb{R}$ is
discrete iff $\mathcal{D}_X$ is finite or countably infinite. 

If $Y$ is a random variable then expression $(Y = y) = \left\{ \zeta \in \omega
: X_{\zeta} = y \right\} $. In other words, $(Y = y)$ denotes the subset of
$\Omega$ whose elements are assigned the value $y$ by the random variable.


\small
\begin{quote}

\textbf{Example.} In a coin toss, a random variable $X$ may assign to the sample
point "heads" the value $1$ and the sample point "tails" the value $-1$. Then
$(X = 1) = 1$, etc.

\end{quote}
\normalsize

We define $P(Y = y) = \sum_{\zeta \in \Omega : Y_{\zeta} = y} P(\zeta)$. The
probability distribution of $Y$ is the general function  

\begin{align*}
    p : \mathbb{R} &\mapsto [0, 1] \\ 
    y &\mapsto P(Y = y)
\end{align*}

Since the probability distribution $p$ is defined as the probability of given
sets of events, it follows that $0 \leq p(y) \leq 1$ for all $y$ and
$sum_{y}p(y) = 1$.

We asume the reader knows the definition of expected value. Let $g : \mathbb{R}
\mapsto \mathbb{R}$. Then $g \circ Y$ (or simply $g(Y)$) has expected value 

\begin{align*}
    \mathbb{E}\left[ g(Y) \right] = \sum_{y \in Im(Y)} g(y)p(y)
\end{align*}


\small
\begin{quote}

    \textbf{Proof.} $P(g(Y) = g_i) = \sum_{y \in Im(Y), g(y) = g_i} p(y)$. Let
    this probability function for $g(Y)$ be called $p_g(y)$. Then 

    \begin{align*}
        \mathbb{E}[g(Y)] &= \sum_{y \in Im(g \circ Y)} y p_g(y) \\ 
                         &= \sum_{y \in Im(g \circ Y)} y \left[ \sum_{x \in
                         Im(Y), g(x)= y} p(x) \right] \\ 
                         &= \sum_{y \in Im(g \circ Y)}  \left[ \sum_{x \in
                         Im(Y), g(x)= y} y p(x) \right] \\ 
                         &= \sum_{x \in Im(y)} g(x)p(x)
    \end{align*}

\end{quote}
\normalsize

\begin{definition}
    Let $\mu = \mathbb{E}\left[ Y \right] $. Then 

    \begin{align*}
        \mathbb{V}\left[ Y \right] = \mathbb{E} \left[ ( Y - \mu )^2 \right] 
    \end{align*}
\end{definition}

\begin{theorem}
    Let $Y$ a random variable with p.m.f. $p$ and $g_1, \ldots, g_k$ functions
    of $Y$. Then 

    \begin{align*}
        \mathbb{E} \left[ g_1(Y) + \ldots + g_k(Y) \right] = \mathbb{E}\left[
        g_1(Y) \right] + \ldots + \mathbb{E}\left[ g_k(Y) \right] 
    \end{align*}
\end{theorem}

\begin{theorem}
    \begin{align*}
    \mathbb{V}[Y] = \mathbb{E}[Y^2] - \mathbb{E}[Y]^2
    \end{align*}
\end{theorem}

This is also easy to prove from the definition of $\mathbb{V}$. 

\pagebreak

\section{Finales}

\subsection{Final 2003-12}

\begin{problem}
    Prove \textit{a.} $P(A \cup B) = P(A) + P(B) - P(A \cap B)$, \textit{b.}
    $P(A \cup B \cup C) = P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B
    \cap C) + P(A \cap B \cap C)$, \textit{c.} $A \subset B \Rightarrow P(A) \leq
    P(B) \land P(B - a) = P(B) - P(A)$.
\end{problem}


\small
\begin{quote}


Let $(\Omega, \mathcal{A}, P)$ be an arbitrary probabilistic model and let $A,
B, C \in \Omega$. 

\textit{(1)} Consider the set $A \cup B$ and let $A \cap B = I$. Observe that

\begin{align*}
    A \cup B = (A \cap B) \cup (A - B) \cup (B - A) \\ 
\end{align*}

Then $P(A \cup B) = P \left( (A \cap B) \cup (A - B) \cup (B-A) \right) $. Since
the intersection of these events is empty, by the axioms of the probability
function we have $P(A \cup B) = P(A \cap B) + P(A - B) + P(B - A)$. Using the
fact that $P(X - Y) = P(X) - P(X \cap Y)$ we have 

\begin{align*}
    P(A \cap B) + P(A) - P(A \cap B) + P(B) - P(B \cap A) = P(A) + P(B) - P(A
    \cap B)
\end{align*}

\textit{(2)}  

\begin{align*}
    P(A \cup B \cup C) &= P(A \cup B) + P(C) - P\left( (A \cup B) \cap C
    \right)\\ 
                       &=P(A) + P(B) + P(C) - P(A \cap B) - P\left( (A \cap C)
                       \cup (B \cap C) \right) \\ 
                       &=P(A) + P(B) + P(C) - P(A \cap B)\\ 
        -&\left[ P(A \cap C) + P(B \cap C) - P(A \cap B \cap C) \right]  \\ 
         &=P(A) + P(B) + P(C) - P(A \cap B) - P(A \cap C) - P(B \cap C) + P(A
         \cap B \cap C) \blacksquare
\end{align*}


\end{quote}
\normalsize

\pagebreak 

\begin{problem}
    Define the variance of a random variable $X$. Show that $\mathbb{V}\left[ cX
    \right] = c^2 \mathbb{V}\left[ X \right], \mathbb{V}\left[ X + Y \right] =
    \mathbb{V}[X] + \mathbb{V}\left[ Y \right]   $ if $X, Y$ independent.
\end{problem}


\small
\begin{quote}

\textit{(1)} The variance of a random variable $X$ is $\mathbb{V}\left[ X
\right] = \mathbb{E}\left[ (X - \mu)^2 \right] $ where $\mu = \mathbb{E}\left[ X
\right] $.

\textit{(2)} Observe that 

\begin{align*}
    \mathbb{V}\left[ cX \right] &= \mathbb{E}\left[ (cX)^2 \right] -
    \mathbb{E}\left[ cX \right]^2 \\ 
                                &=c^2 \mathbb{E} \left[ X^2 \right] -
                                \mathbb{E}\left[ cX \right] \mathbb{E}\left[ cX
                                \right]  \\ 
                                &= c^2 \mathbb{E}\left[ X^2 \right] -c^2
                                \mathbb{E}\left[ X \right] ^2 \\ 
                                &c^2 \left( \mathbb{E}\left[ X^2 \right] - \mu^2
                                \right)  \\ 
                                &c^2 \mathbb{V}\left[ X \right]
\end{align*}

\textit{(3)} 

\begin{align*}
    \mathbb{V}\left[ X + Y\right] &= \mathbb{E}\left[ (X+Y)^2 \right] -
    \mathbb{E}\left[ X + Y \right]^2 \\ 
                                  &=\mathbb{E}\left[ X^2 + 2XY + Y^2 \right] -
                                  \left( \mu_X + \mu_Y \right)^2 \\ 
                                  &=\mathbb{E}\left[ X^2 \right] + 2
                                  \mathbb{E}\left[ XY \right]  +
                                  \mathbb{E}\left[ Y^2 \right] - \mu_X^2 -
                                  2\mu_x\mu_Y - \mu_Y^2 \\ 
    &= \mathbb{E}\left[ X^2 \right] - \mu_X^2 + \mathbb{E}\left[ Y^2 \right] -
    \mu_Y^2 + 2\mathbb{E}\left[ X \right] \mathbb{E}\left[ Y \right] -
    2\mu_x\mu_Y &\{\text{Independence}\}\\ 
    &= \mathbb{V}\left[ X \right] + \mathbb{V}\left[ Y \right] 
\end{align*}

\end{quote}
\normalsize

\pagebreak 

\begin{problem}
    Give a $95\%$ confidence interval for the mean $\mu$ assuming the variance
    $\sigma^2$ is known. Then assuming the variance us unknown.
\end{problem}


\small
\begin{quote}

\textit{(1)} Given a sample $\textbf{x} = X_1, X_2, \ldots, X_n$ with $X_i \sim
\mathcal{N}(\mu, \sigma)$, we can use the fact that $\overline{X} \sim
\mathcal{N}(\mu, \frac{\sigma}{\sqrt{n} } )$ to construct the statistic

\begin{align*}
    Z = \frac{\overline{X} - \mu}{\sigma} \sqrt{n} 
\end{align*}

With sufficiently large $n$, $Z \sim \mathcal{N}(0, 1)$. We want to choose a
value of $Z$ s.t. it occupies $.975$ of the area under the standard normal
curve. Such value is $Z = 1.96$. The confidence interval is then 

\begin{align*}
    \left[ \overline{X} - 1.96 \frac{\sigma}{\sqrt{n} }, \overline{X} + 1.96
    \frac{\sigma}{\sqrt{n} } \right] 
\end{align*}

If $\sigma$ is unknown we would simply use $\hat{\sigma} = \frac{1}{n-1}\sum
(X_i
- \overline{X})^2$ as an estimator and keep everything else the same.

\textit{(2)} If the variance is unknown \textit{and} the sample size is $n \leq
30$, then we must use $\hat{\sigma}$ as before, but use the $t$-Student
distribution. Namely, our confidence interval will now be 

\begin{align*}
    \overline{X} \pm t_{0.025} \hat{\sigma}
\end{align*}

The degrees of freedom of the $t$-Student distribution depends on $n$, of
course.

\end{quote}
\normalsize

\pagebreak 

\begin{problem}
    The number of kids that come to a vending machine during an hour is a
    discrete random variable $Y$ with values in $\{0, 8, 18, 30\}$.
\end{problem}

\textit{(1)} If $P(Y = 8) = \frac{1}{4}, P(Y = 18) = \frac{1}{3},
\mathbb{E}\left[ Y \right] = 13$, what is the value of $P(Y = 30)$?


\small
\begin{quote}

    We know $\mathbb{E}\left[ Y \right] = \sum_{y \in Im(Y)}yp(y) = 8\cdot
    \frac{1}{4} + 18\cdot \frac{1}{3} + 0p(0) + 30p(30) = 13$. Then 

    \begin{align*}
        8 + 30p(30) = 13 \Rightarrow p(30) = \frac{5}{30} = \frac{1}{6}
    \end{align*}

\end{quote}
\normalsize

\textit{(2)} What is the value of $P(Y = 0)$?


\small
\begin{quote}

    We require that $\sum_{y \in Im(Y)}p(y) = 1$. We have 

    \begin{align*}
        \sum_{y \in Im(Y)} p(y) &= \frac{1}{4} + \frac{1}{3} + \frac{1}{6} +
        p(0)\\ 
                                &= \frac{3}{4} + p(0)
    \end{align*}

    Then $\frac{3}{4} + p(0) = 1 \Rightarrow p(0) = \frac{1}{4}$

\end{quote}
\normalsize

\textit{(3)} Find $P(12 \leq Y \leq 20)$ and $P(Y \neq 30)$. 


\small
\begin{quote}

$P(12 \leq Y \leq 20) = P(18) = \frac{1}{3}$. $P(Y \neq 30) = \frac{1}{4} +
\frac{1}{4} + \frac{1}{3} = \frac{5}{6}$ (Consistent with the fact that $1 -
\frac{1}{6} = \frac{5}{6}$)

\end{quote}
\normalsize

\textit{(4)} If each sell makes $1.30$ dollars and it costs $8$ to maintain the
machine for an hour, what is the expected value of the net profit in an hour?


\small
\begin{quote}

The expected number of kids to approach the vending machine is 13. Each spends
$1.30$ dollars with an expected profit of $16.9$. Minus the cost we have an
expected net profit of $8.9$.

\pagebreak 

\begin{problem}
    Let $X_1, X_2, \ldots, X_n$ random sample where each $X_i$ has density 

    \begin{align*}
        f(x) = \begin{cases}
            \frac{1}{2} \left( 1 + \theta x \right) & -1 \leq x \leq 1 \\ 
            0 & otherwise
        \end{cases}
    \end{align*}

    and where $\theta \in [-1, 1]$. Find $\mathbb{E}\left[ X_i \right] $. What
    is the value of $\mathbb{E}\left[ \overline{X} \right] $? If $\hat{\theta} =
    3\overline{X}$, is it an unbiased estimator of $\theta$?
\end{problem}

\end{quote}
\normalsize


\small
\begin{quote}

\textit{(1)} By definition, 

\begin{align*}
    \mathbb{E}\left[ X_i \right] &=\frac{1}{2} \int_{\mathbb{R}} x + \theta x^2 ~
    dx \\ 
                                 &= \frac{1}{2} \left( \int_{-1}^{1} x ~ dx +
                                 \theta \int_{-1}^{1} x^2 ~ dx \right)  \\ 
                                 &= \frac{1}{2} \left( \theta \left[ \frac{1}{3}
                                 + \frac{1}{3} \right]  \right) \\ 
                                 &=\frac{\theta}{3}
\end{align*}

\textit{(2)} Recall that $\overline{X} = \frac{1}{n} \sum X_i$. Then 

\begin{align*}
    \mathbb{E}\left[ \overline{X} \right] = \frac{1}{n}\sum \mathbb{E}\left[ X_i
    \right]  = \frac{\theta}{3}
\end{align*}

\textit{(3)} Since $\mathbb{E}\left[ \overline{X} \right] = \frac{\theta}{3}$ we
have that $\mathbb{E}\left[ 3 \overline{X} \right] = 3 \mathbb{E}\left[
\overline{X} \right]  = \theta$. Thus, by definition, the estimator is unbiased.




\end{quote}
\normalsize

\pagebreak 

\subsection{Final}

\begin{problem}
    En la producción de cierto artículo se pueden presentar sólo dos tipos de
    defectos $A$ y $B$. Se sabe que $A$ ocurre en un $5\%$ de los artículos; $B$
    se presenta en un $3\%$ de los artículos; y ambos ocurren juntos en un $1\%$
    de los artículos.

    \textit{(1)} Dar la probabilidad de que un artículo tomado al azar presente
    $a.$ solamente el defecto tipo $A$, $b.$ al menos un defecto, $c.$ ningún
    defecto. 

    \textit{(2)} Sea $Y$ la variable que cuenta el número de defectos
    encontrados en el artículo elegido al azar. Dé la PDF y la CDF de $Y$.
    Calcule el valor esperado de $X = 2 - Y^2$.
\end{problem}


\small
\begin{quote}

\textit{(1.a)} Sea $\Omega = \left\{ O, A, B, A \cap B \right\} $ y $\mathcal{A}
= \mathcal{P}(\Omega)$. El problema nos da $P(A), P(B), P(A \cap B)$. Nos
interesa ahora $P(A - B)$. Evidentemente $A - B \in \mathcal{A}$ y por lo tanto
está bien definida la probabilidad. Veamos que

\begin{align*}
    P(A - B) &= P(A) - P(A \cap B) \\ 
             &= .05 - .01 \\ 
             &= .04
\end{align*}

\textit{(1.b)} El conjunto deseado es ${A} \cup {B}$, pero
sabemos que ${A}, {B}$ no son disjuntos. Entonces usamos el
hecho de que $P({A} \cup {B}) = P({A}) + P({B})
- P({A} \cap {B})$. Esto da fácilmente $.05 + .03 - .01 = .07$. 

\textit{(1.c)} La probabilidad de que un elemento tenga algún error cualquiera
es la probabilidad de que tenga solamente un error de tipo $A$, solamente un
error de tipo $B$, o ambos. Esto es, $P(\overline{O}) = .04 + .03 + .01 = .08$.
Luego $P(O) = .92$. (Otra forma de verlo es tomar directamente $P(A \cup B) =
P(A) + P(B) - P(A \cap B) = .08$).

\textit{(2)} Sabemos por el punto \textit{(1)} que $P(Y = 2) = .01, P(Y = 1) =
.07, P(Y = 0) = .98$. Es decir, 

\begin{align*}
    p(y)_Y = \begin{cases}
        .92 & y = 0 \\ 
        .07 & y = 1 \\ 
        .01 & y = 2
    \end{cases}
\end{align*}

Esto implica que 

\begin{align*}
    F(y)_Y = \begin{cases}
        0 &= .92 \\ 
        1  &= .99 \\ 
        2 &= 1
    \end{cases}
\end{align*}

El valor esperado de $2 - Y^2$ es $2 - \mathbb{E}[Y^2]$. Es fácil observar que

\begin{align*}
    \mathbb{E}\left[ Y^2 \right]  = .07^2 + .01^2 \times 2 = .0053
\end{align*}

Luego el valor esperado de $2 - Y^2$ es $1.9947$.

\end{quote}
\normalsize

\pagebreak

\begin{problem}
    Una unidad de radar es usada para medir la velocidad de los automóviles en
    una vía durante la hora de mayor congestionamiento. La velocidad de los
    automóviles está normalmente distribuida con distribución $\mathcal{N}(100,
    8.5)$. \textit{(1)} Dé la probabilidad de que un auto elegido al azar viaje
    a una velocidad de a lo sumo $85$. \textit{(2)} Dé la probabilidad de que
    viaje a una velocidad entre $58$ y $110$. \textit{(3)} Dé la probabilidad de
    que uno de diez automóviles elegidos al azar viaje a una velocidad mayor a
    $88$.
\end{problem}

\textit{(1)} Estandarizamos la variable y utilizamos la distribución normal
estándar. Si $X \sim \mathcal{N}(100, 8.5)$ denota la variable de interés
(velocidad de un vehículo en el contexto del problema),

\begin{align*}
    P(X \leq 85) = \Phi \left( \frac{88 - 100}{8.5} \right) = \Phi(-1.411)
\end{align*}

La tabla de la distribución estándar da $\Phi(-1.764) = .079$. Es decir, la
probabilidad de que un vehículo viaje a a lo sumo $85$ km/h es $7.9\%$.

\textit{(2)} Según la misma lógica, 

\begin{align*}
    P(58 \leq X \leq 110) &= \Phi \left( \frac{110 - 100}{8.5} \right) - \Phi
    \left( \frac{58 - 100}{8.5} \right) \\ &= \Phi(1.176) - \Phi(-4.941) \\
                                           &=.879 - 0 \\ &=.879
\end{align*}

\textit{(3)} Digamos que el evento de obtener un vehículo que viaje a más de
$88$ km/h es un éxito, y cualquier otro caso un fallo. Evidentemente la cantidad
de vehículos que superan $88$ km/h en una muestra de diez sigue
sigue una distribución binomial $Y \sim \mathcal{B}\left( P(X
\geq 88), 10 \right) $. Se nos pide la probabilidad de que haya exactamente un
éxito. Calculemos $p = P(X \geq 88)$. Evidentemente esto es $1 - P(X \leq 88) =
1 - .079 = .921$. Se sigue que  

\begin{align*}
    P(Y = 1) &= \binom{10}{1}\cdot .921 \cdot (1 - .921)^{9} \\ 
             &= 10 \cdot .921 \cdot 0 \\ 
             &\approx 0
\end{align*}

\pagebreak 

\begin{problem}
    Sea $X_i \sim \mathcal{N}(\mu, \sigma)$. Asumamos una muestra de $X_1,
    \ldots, X_{18}$  una muestra con media muestral $\overline{X} = 99.45$ y
    desviación estándar $s_2 =
    1.3$. Dé estimaciones de máxima verosimilitud para la media, la varianza y
    el percentil $5\%$. Construya un intervalo de confianza del $99\%$ para la
    media poblacional.
\end{problem}

Haremos solo el intervalo de confianza. La varianza poblacional es desconocida y
la cantidad de datos es menor a $30$. Usaremos la distribución $t$ de Student.
Recordemos que la media muestral sigue una distribución $\mathcal{N}(\mu,
\frac{\sigma}{\sqrt{n} })$. Usaremos el estadístico

\begin{align*}
    t = \frac{\overline{X} - \mu}{1.3}\sqrt{18} 
\end{align*}

Sabemos que $t$ sigue una distribución $t$ de Student con $17$ grados de
libertad. Queremos determinar el intervalo 

\begin{align*}
    \overline{X} \pm \frac{1.3}{\sqrt{18} } t_{.005}
\end{align*}

(Vea que $\alpha = .01 \Rightarrow \frac{\alpha}{2} = .005$). Usando la table de
la distribución $t$ de Student, tenemos 

\begin{align*}
    \overline{X} \pm \frac{1.3}{\sqrt{18} } 2.567 = \mu \pm 0.30 \times 2.567
\end{align*}

Esto resulta en

\begin{align*}
    99.45 \pm .7701 = \left[ 98.6799, 100.2201 \right] 
\end{align*}

\pagebreak 

\begin{problem}
    En el diseño de mascarillas de bomberos se prueba un conjunto de $120$
    mascarillas. $48$ fallaron la prueba. Dé un intervalo de conianza del $90\%$
    para $p$. Determine el tamaño de muestra necesario para que un intervalo de
    confianza del $90\%$ tenga una longitud de a lo sumo la mitad de la obtenida
    en el item anterior, independientemente del valor de $\hat{p}$.

    Si se quiere determinar si hay suficiente evidencia para decir que $p$ es
    menor a $0.5$, plantee las hipótesis, establezca la región de rechazo con
    nivel de significación del $5\%$, calcule el $p$-valor y tome una decisión
    dado $\alpha = 0.01$.
\end{problem}

\textit{(1)} Tenemos $\hat{p} = \frac{48}{120} = 0.4$. Para muestras
suficientemente grandes, el estimador sigue una distribución normal. Sabemos que
la desviación estándar de este estimador es 

\begin{align*}
    \hat{s} = \sqrt{\frac{0.4 \cdot 0.6}{120}} = 0.044
\end{align*}

Entonces, usamos el estadístico

\begin{align*}
    Z = \frac{0.4 - p}{0.044}
\end{align*}

que sigue una distribución normal estándar y calculamos el intervalo 

\begin{align*}
    0.4 \pm 0.044 z_{.05} &= 0.4 \pm 0.044 \times 1.645 \\ 
    &=0.4 \pm 0.072 \\ 
    &= [.328, .472]
\end{align*}

\textit{(2)} La longitud del intervalo obtenido es $.144$. El tamaño de muestra
rnecesario para que el intervalo tenga una longitud de $.\frac{144}{2} = .072$,
independientemente del valor de $\overline{p}$,
es dada por la ecuación 

\begin{align*}
    \bar{p} + \sqrt{\frac{\bar{p}(1-\bar{p})}{{n} }} 1.645 - \left(\bar{p}
    - \sqrt{\frac{\bar{p}(1-\bar{p})}{{n} }} 1.645\right) &\leq .072 \\ 
    2 \sqrt{\frac{\hat{p}(1 - \hat{p})}{n }} &\leq .072 \\ 
    \hat{p}(1 - \hat{p}) &\leq
                                                    .001 n \\ 
                                                    \frac{\hat{p}(1 -
\hat{p})}{.001} &\leq n
\end{align*}

Si hacemos $u = \hat{p}(1 - \hat{p})$ y observamos que $\frac{1}{.001}
= \frac{1}{\frac{1}{1000}}=1000$, tenemos que $n \geq 1000u$ es el tamaño de
muestra necesario para que el intervalo tenga la longitud deseada o menos. En el
caso particular de nuestra $\hat{p} = 0.4$, deberíamos tener $240$
observaciones. Observe que esto es el doble de las observaciones que tenemos $(n
= 120)$. Esto tiene sentido, pues se nos pidió reducir la longitud del intervalo
a la mitad.


\textit{(3)} Hagamos la prueba de hipótesis. Sea $H_0 : p = 0.5$. La hipótesis
alternativa será $H_1 : p < 0.5$.

Asuma que la hipótesis nula es verdadera. ¿Cuál es la probabilidad de haber
encontrado $\hat{p} = 0.4$ en este caso? Si la hipótesis nula fuera
verdadera, la desviación estándar debería ser $\sqrt{\frac{0.5^2}{120}} = .045
$. El valor observado $\hat{p}$ estaría entonces a

\begin{align*}
    z = \frac{0.4 - 0.5}{.045} = -2.222
\end{align*}

desviaciones estándar de la media. El $p$-valor será el área de la distribución
normal estándar a la izquierda de $-2.222$---es decir, la probabilidad de
observar un valor tan o más extremo que $-2.222$---. Tomamos el área a la
izquierda porque la hipótesis alternativa es que $p$ es \textit{menor} a es
$0.5$. Entonces, la tabla de la distribución normal nos dice que $p\text{-valor}
= .0132$. Como esto es superior a $\alpha = 0.01$, no rechazamos la hipótesis
nula.

\pagebreak 

\begin{problem}
    Sea $X_1, \ldots, X_n$ una muestra con $n \geq 3$ y $X_i \sim
    \text{Poisson}(\lambda)$. \textit{(1)} Encuentre el estimador de $\lambda$
    usando el método de los momentos. \textit{(2)} Encuentre el estimador de
    $\lambda$ usando máxima verosimilitud. \textit{(3)} Considere los
    estimadores 

    \begin{align*}
        \overline{\lambda_1} = X_1, \overline{\lambda_2} = \frac{X_1 + X_n}{2},
        \overline{\lambda_3} = \frac{X_1 + 2X_2 + X_3}{3}, \overline{\lambda_4}
        = \overline{X}
    \end{align*}

    ¿Cuál es insesgado? ¿Cuál tiene menor varianza?
\end{problem}

Recuerde que si $X \sim \text{Poisson}(\lambda)$ entonces $f(x) = e^{-\lambda}
\frac{\lambda^x}{x!}$ para $x \geq 0$.

\textit{(1)} El primer momento muestral es $\overline{X}$. El primer momento (o
la esperanza) de una Poisson es su parámetro $\lambda$. Igualando ambos
obtenemos $\overline{X} = \lambda$ y vemos que la media muestral es un estimador
por el método de los momentos de $\lambda$. 

Usando máxima verosimilitud, observemos que 

\begin{align*}
    \mathcal{L}(\lambda \mid X_1, \ldots, X_n) &= \prod_{i=1}^{n} f(x_i \mid
    \lambda)   \\ 
\end{align*}

We can find the maximizing value of $\lambda$ for this probability by finding
the maximizing $\lambda$ for 

\begin{align*}
    \sum_{i=1}^{n} \ln \left( f(x_i \mid \lambda) \right) &= \sum_{i=1}^{n} \ln
    \left( e^{-\lambda} \frac{\lambda^{x_i}}{(x_i)!} \right)  \\ 
                                                          &= \sum_{i=1}^{n}
                                                          \left[\ln(e^{-\lambda}) +
                                                          \ln(\lambda^{x_i}) -
                                                      \ln( x_i! )\right] \\ 
                                                          &= \ln(e^{-\lambda}) +
                                                          \sum_{i=1}^{n}
                                                          \ln(\lambda^{x_i}) -
                                                          \ln(x_i!)
\end{align*}

Pues $\ln(x_i!)$  no depende de $\lambda$, será superfluo en la maximzación (en
la derivada será cero) y por lo tanto maximizamos encontrando

\begin{align*}
    \frac{\partial }{\partial \lambda} \left[\ln(e^{-\lambda}) + \sum_{i=1}^{n}
    \ln(\lambda^{x_i})\right] &= 0 \\ 
    \frac{\partial \ln(e^u)}{\partial u}\frac{\partial u}{\partial \lambda} +
    \sum_{i=1}^{n} \frac{\partial \ln(\lambda^{x_i})}{\partial \lambda } &= 0
                                                                         &\{u =
                                                                         -\lambda\}
                                                                         \\ 
    -u + \sum_{i=1}^{n} \left( \frac{\partial \ln w}{\partial w}\frac{\partial
w}{\partial \lambda} \right) &= 0 &\{w = \lambda^{x_i}\} \\ 
-u + \sum_{i=1}^{n} \frac{1}{w} x_i\lambda^{x_i - 1} &= 0 \\ 
\lambda + \sum_{i=1}^{n} \frac{\lambda^{x_i - 1}}{\lambda^{x_i}}x_i &= 0 \\ 
\lambda + \sum_{i=1}^{n} \frac{x_i}{\lambda^{x_i}} &= 0
\end{align*}



\end{document}


